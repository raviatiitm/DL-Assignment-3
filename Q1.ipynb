{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jYPFwHOUaO"
      },
      "outputs": [],
      "source": [
        "# getting data files path\n",
        "train_path = \"/content/hin_train.csv\"\n",
        "val_path = \"/content/hin_valid.csv\"\n",
        "test_path = \"/content/hin_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNh8EaeDOh7a"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import torchvision\n",
        "import zipfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HIrs9IvNOlu1"
      },
      "source": [
        "## **Data PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAAo52mZOh4p"
      },
      "outputs": [],
      "source": [
        "def getWords(path):\n",
        "    hindi = []\n",
        "    english = []\n",
        "\n",
        "    file = open(path)\n",
        "    dataset = csv.reader(file, delimiter=\",\")\n",
        "\n",
        "    # to get the words in a list\n",
        "\n",
        "    for data in dataset:\n",
        "        e = data[0]\n",
        "        h = data[1]\n",
        "        english.append(e)\n",
        "        hindi.append(h)\n",
        "\n",
        "    # appending the start and end characters to hindi words\n",
        "    for i in range(len(hindi)):\n",
        "        hindi[i] = \"\\t\" + hindi[i] + \"\\n\"\n",
        "\n",
        "    return np.array(hindi), np.array(english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDRd7_AXOh2F"
      },
      "outputs": [],
      "source": [
        "def getChar(data):\n",
        "    data_char = set()  # to store the the unique characters present in data\n",
        "    data_char.add(\" \")\n",
        "    for word in data:\n",
        "        for char in word:\n",
        "            if char not in data_char:\n",
        "                data_char.add(char)\n",
        "\n",
        "    # sort the characters in dataset\n",
        "    data_char = sorted(list(data_char))\n",
        "\n",
        "    # number of characters in the set\n",
        "    num_tokens = len(data_char)\n",
        "\n",
        "    # get the max length of the words\n",
        "    max_len = max([len(word) for word in data])\n",
        "\n",
        "    # return set of all characters in data\n",
        "    return data_char, num_tokens, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuiYz61lOhzk"
      },
      "outputs": [],
      "source": [
        "def getData(\n",
        "    english,\n",
        "    hindi,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        "):\n",
        "    # initializing with 0s for max_length\n",
        "    encoder_input_data = np.zeros((len(english), max_enc_len), dtype=\"float32\")\n",
        "    decoder_input_data = np.zeros((len(english), max_dec_len), dtype=\"float32\")\n",
        "\n",
        "    # creating indices for characters that exist\n",
        "    for i, (english, hindi) in enumerate(zip(english, hindi)):\n",
        "        for t, char in enumerate(english):\n",
        "            encoder_input_data[i, t] = input_token_index[char]\n",
        "\n",
        "        for t, char in enumerate(hindi):\n",
        "            decoder_input_data[i, t] = target_token_index[char]\n",
        "        decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "\n",
        "    return encoder_input_data, decoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojQyJjfdOhxO"
      },
      "outputs": [],
      "source": [
        "def createDictionary(input_tokens, target_tokens):\n",
        "    # making a dictionary to map the characters with the indices\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_tokens)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_tokens)])\n",
        "\n",
        "    # making a dictionary to map the indices with the characters\n",
        "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "    reverse_target_char_index = dict(\n",
        "        (i, char) for char, i in target_token_index.items()\n",
        "    )\n",
        "    return (\n",
        "        input_token_index,\n",
        "        target_token_index,\n",
        "        reverse_input_char_index,\n",
        "        reverse_target_char_index,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsOA5hE8Ohum"
      },
      "outputs": [],
      "source": [
        "# get the training words as an array from train data\n",
        "train_hindi_words, train_english_words = getWords(train_path)\n",
        "# get validation words\n",
        "val_hindi_words, val_english_words = getWords(val_path)\n",
        "# get test words\n",
        "test_hindi_words, test_english_words = getWords(test_path)\n",
        "\n",
        "\n",
        "# get the characters from train and val and test dataset\n",
        "train_eng_characters, train_num_encoder_tokens, train_max_enc_len = getChar(\n",
        "    train_english_words\n",
        ")\n",
        "train_hin_characters, train_num_decoder_tokens, train_max_dec_len = getChar(\n",
        "    train_hindi_words\n",
        ")\n",
        "\n",
        "val_eng_characters, val_num_encoder_tokens, val_max_enc_len = getChar(val_english_words)\n",
        "val_hin_characters, val_num_decoder_tokens, val_max_dec_len = getChar(val_hindi_words)\n",
        "\n",
        "test_eng_characters, test_num_encoder_tokens, test_max_enc_len = getChar(\n",
        "    test_english_words\n",
        ")\n",
        "test_hin_characters, test_num_decoder_tokens, test_max_dec_len = getChar(\n",
        "    test_hindi_words\n",
        ")\n",
        "\n",
        "# take the largest number of tokens and max_length of words on both encoder and decoder\n",
        "num_encoder_tokens = max(\n",
        "    val_num_encoder_tokens, train_num_encoder_tokens, test_num_encoder_tokens\n",
        ")\n",
        "num_decoder_tokens = max(\n",
        "    val_num_decoder_tokens, train_num_decoder_tokens, test_num_decoder_tokens\n",
        ")\n",
        "\n",
        "max_enc_len = max(train_max_enc_len, val_max_enc_len, test_max_enc_len)\n",
        "max_dec_len = max(train_max_dec_len, val_max_dec_len, test_max_dec_len)\n",
        "\n",
        "# finding the set having unique characters from train, val,test data\n",
        "input_hin_characters = set()\n",
        "for char in train_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "for char in val_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "for char in test_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "\n",
        "# calling createDictionary function to make a dictionary and reverse dictionary to map the characters with the indices and indices to characters\n",
        "(\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        "    reverse_input_char_index,\n",
        "    reverse_target_char_index,\n",
        ") = createDictionary(train_eng_characters, list(input_hin_characters))\n",
        "\n",
        "# creating input data for encoder and decoder to process in batch\n",
        "train_encoder_input_data, train_decoder_input_data = getData(\n",
        "    train_english_words,\n",
        "    train_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "val_encoder_input_data, val_decoder_input_data = getData(\n",
        "    val_english_words,\n",
        "    val_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "test_encoder_input_data, test_decoder_input_data = getData(\n",
        "    test_english_words,\n",
        "    test_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "\n",
        "# converting to tensors from numpy\n",
        "train_encoder_input_data = torch.from_numpy(train_encoder_input_data).to(device).long()\n",
        "train_decoder_input_data = torch.from_numpy(train_decoder_input_data).to(device).long()\n",
        "\n",
        "val_encoder_input_data = torch.from_numpy(val_encoder_input_data).to(device).long()\n",
        "val_decoder_input_data = torch.from_numpy(val_decoder_input_data).to(device).long()\n",
        "\n",
        "test_encoder_input_data = torch.from_numpy(test_encoder_input_data).to(device).long()\n",
        "test_decoder_input_data = torch.from_numpy(test_decoder_input_data).to(device).long()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdu6HP9pO4Ql"
      },
      "source": [
        "##**Encoder Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ULn_CaOOhru"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, cell, embedding_size, hidden_size, no_of_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        # setting the encoder part\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_token_index_len = len(input_token_index)\n",
        "        self.no_of_layers = no_of_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        self.cell = cell\n",
        "        self.train_eng_characters = train_eng_characters\n",
        "        self.drop = nn.Dropout(dropout)  # using dropout\n",
        "        # creating an embedding layer\n",
        "        self.encoder_embedding = nn.Embedding(\n",
        "            self.input_token_index_len, self.embedding_size\n",
        "        ).to(device)\n",
        "        self.gru = nn.GRU(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "        self.rnn = nn.RNN(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "        self.lstm = nn.LSTM(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "\n",
        "    # forward function for encoder\n",
        "    def forward(self, input, hidden, cell):\n",
        "        enc_embedd = self.encoder_embedding(input)\n",
        "        temp = enc_embedd\n",
        "        # using dropout\n",
        "        enc_embedd = self.drop(temp)\n",
        "        # RNN/GRU/LSTM layer of the encoder\n",
        "        if self.cell == \"RNN\":\n",
        "            input1 = enc_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.rnn(input1, input2)\n",
        "        elif self.cell == \"GRU\":\n",
        "            input1 = enc_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.gru(input1, input2)\n",
        "        elif self.cell == \"LSTM\":\n",
        "            input1 = enc_embedd\n",
        "            output, (hidden, cell) = self.lstm(input1, (hidden, cell))\n",
        "        return output, (hidden, cell)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bU-9PZCgO-fs"
      },
      "source": [
        "## **Decoder Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoPlFOvpOhpG"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, cell, embedding_size, hidden_size, no_of_layers, dropout, batchsize\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        # setting the encoder part\n",
        "        self.cell = cell\n",
        "        self.no_of_layers = no_of_layers\n",
        "        self.target_token_index_len = len(target_token_index)\n",
        "        self.drop = nn.Dropout(dropout)  # using dropout\n",
        "        self.embedding_size = embedding_size\n",
        "        self.train_hin_characters = train_hin_characters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batchsize = batchsize\n",
        "        # creating an embedding layer\n",
        "        self.decoder_embedding = nn.Embedding(\n",
        "            self.target_token_index_len, self.embedding_size\n",
        "        ).to(device)\n",
        "        input1 = embedding_size + hidden_size * 2\n",
        "        self.lstm = nn.LSTM(\n",
        "            input1, hidden_size, self.no_of_layers, batch_first=True\n",
        "        ).to(device)\n",
        "        input2 = embedding_size + hidden_size * 2\n",
        "        self.rnn = nn.RNN(input2, hidden_size, self.no_of_layers, batch_first=True).to(\n",
        "            device\n",
        "        )\n",
        "        input3 = embedding_size + hidden_size * 2\n",
        "        self.gru = nn.GRU(input3, hidden_size, self.no_of_layers, batch_first=True).to(\n",
        "            device\n",
        "        )\n",
        "        input4 = self.target_token_index_len\n",
        "        self.linear = nn.Linear(self.hidden_size, input4, bias=True).to(device)\n",
        "        self.softmax = nn.Softmax(dim=2).to(device)\n",
        "\n",
        "    # using forward function for decoder\n",
        "    def forward(self, input, hidden, cell, hiddenj):\n",
        "        dec_embedd = self.decoder_embedding(input)\n",
        "        temp1 = hiddenj[0].reshape(self.batchsize, 1, self.hidden_size)\n",
        "        temp2 = hiddenj[1].reshape(self.batchsize, 1, self.hidden_size)\n",
        "        dec_embedd = torch.cat((dec_embedd, temp1, temp2), dim=2)\n",
        "        dec_embedd = self.drop(dec_embedd)\n",
        "        # RNN/GRU/LSTM layer of the decoder\n",
        "        if self.cell == \"LSTM\":\n",
        "            input1 = dec_embedd\n",
        "            output, (hidden, cell) = self.lstm(dec_embedd, (hidden, cell))\n",
        "        elif self.cell == \"RNN\":\n",
        "            input1 = dec_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.rnn(input1, input2)\n",
        "        elif self.cell == \"GRU\":\n",
        "            input1 = dec_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.gru(input1, input2)\n",
        "        output = self.linear(output)\n",
        "        temp = (hidden, cell)\n",
        "        return output, temp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U8vtjxa1i1TU"
      },
      "source": [
        "## **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN8JRnLxPDUt"
      },
      "outputs": [],
      "source": [
        "# function to get batchsize of data\n",
        "def getBatchData(input, batchsize, x):\n",
        "    return input[x : x + batchsize]\n",
        "\n",
        "\n",
        "# function to do split as output is also biredictional output as encoder is bidirectional. So we are splitting it.\n",
        "def getSplit(output, hidden_size):\n",
        "    temp = torch.split(output, [hidden_size, hidden_size], dim=2)\n",
        "    input1 = temp[0]\n",
        "    input2 = temp[1]\n",
        "    temp = torch.add(input1, input2) / 2\n",
        "    return temp\n",
        "\n",
        "\n",
        "# function to do resize as encoder is bidirectional asnd decoder is unidirectional. so we are reshaping it.\n",
        "def getResize(var, val, no_of_layers, batchsize, hidden_size):\n",
        "    var = var.reshape(2, no_of_layers, batchsize, hidden_size)\n",
        "    var = torch.add(var[0], var[1]) / 2\n",
        "    return var\n",
        "\n",
        "\n",
        "# function to concatenate and return as tuple\n",
        "def getConcatenation(lst):\n",
        "    temp = torch.cat(tuple(x for x in lst), dim=1).to(device)\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfB_3n-TPNxS"
      },
      "outputs": [],
      "source": [
        "# function to calculate accuracy\n",
        "def getAccuracy(target, output):\n",
        "    n = len(target)\n",
        "    total = 0\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        if torch.equal(target[i], output[i]):\n",
        "            total += 1\n",
        "        i += 1\n",
        "    return total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xIfk6bHNUTJk"
      },
      "source": [
        "## **Function for validation data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrynLImkUN87"
      },
      "outputs": [],
      "source": [
        "def getValidation(\n",
        "    attention,\n",
        "    val_encoder_input_data,\n",
        "    val_decoder_input_data,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    batchsize,\n",
        "    hidden_size,\n",
        "    embedding_size,\n",
        "    no_of_layers,\n",
        "):\n",
        "    with torch.no_grad():\n",
        "        temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "        enc_hidden = temp\n",
        "        enc_cell = temp\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for x in range(0, len(val_encoder_input_data), batchsize):\n",
        "            y_pred = []\n",
        "            y_actual = []\n",
        "            loss = 0\n",
        "            # input for encoder\n",
        "            input_tensor = getBatchData(val_encoder_input_data, batchsize, x).to(device)\n",
        "            # calling encoder forward function\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            output = getSplit(output, hidden_size)\n",
        "            # input for first hidden state in decoder\n",
        "            input = (\n",
        "                val_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )\n",
        "            # calling resize because encoder is bidirectional\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            k = 0\n",
        "            temp1 = output if attention else hiddenj\n",
        "            # ruuning while loop for max no of characters in decoder data\n",
        "            while k < max_dec_len:\n",
        "                output1, (hidden, cell) = decoder.forward(input, hidden, cell, temp1)\n",
        "                output2 = decoder.softmax(output1)\n",
        "                output3 = torch.argmax(output2, dim=2)\n",
        "                y_pred.append(output1)  # storing decoder predicted value\n",
        "                y_actual.append(output3)  # storing decoder predicted value index\n",
        "                input = output3\n",
        "                k += 1\n",
        "            # flattening the tensor\n",
        "            y_pred = getConcatenation(y_pred).reshape(\n",
        "                max_dec_len * batchsize, len(target_token_index)\n",
        "            )\n",
        "            y_actual = getConcatenation(y_actual)\n",
        "            var = val_decoder_input_data[x : x + batchsize]\n",
        "            total_acc += getAccuracy(\n",
        "                var.to(device), y_actual\n",
        "            )  # calling accuracy function to get accuracy\n",
        "            # calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
        "                y_pred, var.reshape(-1).to(device)\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "        denom = len(val_decoder_input_data) * max_dec_len\n",
        "        val_loss = total_loss / denom  # calculating val loss\n",
        "        total_loss = 0\n",
        "        # calculating val accuracy\n",
        "        val_accuracy = total_acc / len(val_decoder_input_data)\n",
        "        val_accuracy = val_accuracy * 100\n",
        "        total_acc = 0\n",
        "        return val_loss, val_accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y312AlwRPyYh"
      },
      "source": [
        "## **Train Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEseFzv2PRME"
      },
      "outputs": [],
      "source": [
        "def train(rnn, batchsize, hidden_size, embedding_size, no_of_layers, dropout, epochs):\n",
        "    teacher_ratio = 0.5\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    learning_rate = 0.001\n",
        "    # creating encoder and decoder model\n",
        "    encoder = Encoder(rnn, embedding_size, hidden_size, no_of_layers, dropout).to(\n",
        "        device\n",
        "    )\n",
        "    decoder = Decoder(\n",
        "        rnn, embedding_size, hidden_size, no_of_layers, dropout, batchsize\n",
        "    ).to(device)\n",
        "    opt_encoder = optim.Adam(encoder.parameters(), learning_rate)\n",
        "    opt_decoder = optim.Adam(decoder.parameters(), learning_rate)\n",
        "    loss = 0\n",
        "    # running for loop epochs no of times\n",
        "    for i in range(epochs):\n",
        "        print(\"Epoch---\", i + 1, end=\" \")\n",
        "        # getting batchsize amount of encoder data\n",
        "        for x in range(0, len(train_encoder_input_data), batchsize):\n",
        "            y_pred = []  # to store predicted value by decoder to calculate loss\n",
        "            y_val = (\n",
        "                []\n",
        "            )  # to store index of predicted value by decoder to calculate accuracy\n",
        "            hidden_input = torch.zeros(no_of_layers, batchsize, hidden_size).to(\n",
        "                device\n",
        "            )  # initial input to first hidden state(S0)\n",
        "            temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "            input_tensor = getBatchData(train_encoder_input_data, batchsize, x).to(\n",
        "                device\n",
        "            )  # to get batchsize of train data for encoder\n",
        "            input_tensor_size = input_tensor.size()[0]\n",
        "            # initializing with zeroes\n",
        "            enc_hidden = temp\n",
        "            enc_cell = temp\n",
        "            if batchsize > input_tensor_size:\n",
        "                break\n",
        "            # calling forward function of encoder\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            input = (\n",
        "                train_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )  # to get batchsize amount of decoder input data for first hidden state\n",
        "            # doing the resizeing for bidirectional implementation\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            # using teacher forcing\n",
        "            teacher_forcing = True if random.random() < teacher_ratio else False\n",
        "            k = 0\n",
        "            if teacher_forcing:\n",
        "                # runing while loop for max no of characters in decoder data\n",
        "                while k < max_dec_len:\n",
        "                    output1, (hidden, cell) = decoder.forward(\n",
        "                        input, hidden, cell, hiddenj\n",
        "                    )  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    y_pred.append(output1)  # storing decoder predicted value\n",
        "                    y_val.append(output3)  # storing decoder predicted value index\n",
        "                    input = (\n",
        "                        train_decoder_input_data[x : x + batchsize, i]\n",
        "                        .to(device)\n",
        "                        .reshape(batchsize, 1)\n",
        "                    )  # giving groung truth data for next input\n",
        "                    k += 1\n",
        "            else:\n",
        "                while k < max_dec_len:\n",
        "                    output1, (hidden, cell) = decoder.forward(\n",
        "                        input, hidden, cell, hiddenj\n",
        "                    )  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    y_pred.append(output1)  # storing decoder predicted value\n",
        "                    y_val.append(output3)  # storing decoder predicted value index\n",
        "                    input = output3  # giving last output as next input\n",
        "                    k += 1\n",
        "            # flattening the tensor\n",
        "            y_pred = (\n",
        "                getConcatenation(y_pred)\n",
        "                .to(device)\n",
        "                .reshape(max_dec_len * batchsize, len(target_token_index))\n",
        "            )  #\n",
        "            y_val = getConcatenation(y_val)\n",
        "            var = getBatchData(train_decoder_input_data, batchsize, x)\n",
        "            total_acc += getAccuracy(\n",
        "                var.to(device), y_val\n",
        "            )  # calling accuracy function to get accuracy\n",
        "            # calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
        "                y_pred, var.reshape(-1).to(device)\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "            loss.backward(retain_graph=True)\n",
        "            # clipping the gradient\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "            opt_encoder.step()\n",
        "            opt_decoder.step()\n",
        "            opt_encoder.zero_grad()\n",
        "            opt_decoder.zero_grad()\n",
        "            loss = 0\n",
        "        denom = len(train_decoder_input_data) * max_dec_len\n",
        "        training_loss = total_loss / denom  # calculating training loss\n",
        "        # calculating training accuracy\n",
        "        training_accuracy = (total_acc / len(train_decoder_input_data)) * 100\n",
        "        # calling getValidation to get validation loss and accuracy\n",
        "        validation_loss, validation_accuracy = getValidation(\n",
        "            False,\n",
        "            val_encoder_input_data,\n",
        "            val_decoder_input_data,\n",
        "            encoder,\n",
        "            decoder,\n",
        "            batchsize,\n",
        "            hidden_size,\n",
        "            embedding_size,\n",
        "            no_of_layers,\n",
        "        )\n",
        "        print(\n",
        "            \" Train loss = \",\n",
        "            training_loss,\n",
        "            \" Train accuracy = \",\n",
        "            training_accuracy,\n",
        "            \"   validation loss= \",\n",
        "            validation_loss,\n",
        "            \"  validation accuaracy= \",\n",
        "            validation_accuracy,\n",
        "        )\n",
        "        total_loss = 0\n",
        "        total_acc = 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
