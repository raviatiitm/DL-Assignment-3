{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jYPFwHOUaO"
      },
      "outputs": [],
      "source": [
        "#getting data files path\n",
        "train_path = \"/content/hin_train.csv\"\n",
        "val_path = \"/content/hin_valid.csv\"\n",
        "test_path = \"/content/hin_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import torchvision\n",
        "import zipfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "CNh8EaeDOh7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax135O61Y7mO",
        "outputId": "b789b9a1-fc36-4f77-86e4-46c710accb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=686a9e89b57ebe9095639f07f4c6e21d31bbfd487308d7a589c6237ddae3e84e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "_7urLxX9Y-S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "421IwO8nZBqU",
        "outputId": "3cec24cd-fde0-4b13-ab96-3190a60a2ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil\n",
        "import torch\n",
        "from numba import cuda\n",
        "from GPUtil import showUtilization as gpu_usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yvtseS8ZKLk",
        "outputId": "ee759e8b-c8da-4339-b89d-d2188d5593b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=19e75e39fc63d8c69578753f0c33df092712dbe2c0b998e6ef5438a14bb5ab61\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data PreProcessing**"
      ],
      "metadata": {
        "id": "HIrs9IvNOlu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getWords(path):\n",
        "        \n",
        "        hindi = []\n",
        "        english = []\n",
        "\n",
        "        file = open(path)\n",
        "        dataset = csv.reader(file, delimiter = \",\")\n",
        "\n",
        "        # to get the words in a list\n",
        "\n",
        "        for data in dataset:\n",
        "          e=data[0]\n",
        "          h=data[1]\n",
        "          english.append(e)\n",
        "          hindi.append(h)\n",
        "\n",
        "        #appending the start and end characters to hindi words\n",
        "        for i in range(len(hindi)):\n",
        "            hindi[i] = \"\\t\" + hindi[i] +\"\\n\"\n",
        "\n",
        "        return np.array(hindi), np.array(english)"
      ],
      "metadata": {
        "id": "vAAo52mZOh4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getChar(data):\n",
        "      data_char = set() #to store the the unique characters present in data\n",
        "      data_char.add(\" \")\n",
        "      for word in data:\n",
        "        for char in word:\n",
        "          if char not in data_char:\n",
        "            data_char.add(char)\n",
        "\n",
        "      #sort the characters in dataset\n",
        "      data_char = sorted(list(data_char))\n",
        "\n",
        "      #number of characters in the set\n",
        "      num_tokens = len(data_char)\n",
        "\n",
        "      #get the max length of the words\n",
        "      max_len = max([len(word) for word in data])\n",
        "\n",
        "      #return set of all characters in data\n",
        "      return data_char, num_tokens, max_len "
      ],
      "metadata": {
        "id": "WDRd7_AXOh2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(english, hindi, max_enc_len, max_dec_len, num_decoder_tokens, input_token_index, target_token_index):\n",
        "      #initializing with 0s for max_length\n",
        "      encoder_input_data = np.zeros((len(english), max_enc_len), dtype=\"float32\") \n",
        "      decoder_input_data = np.zeros((len(english), max_dec_len), dtype=\"float32\") \n",
        "\n",
        "      #creating indices for characters that exist\n",
        "      for i, (english, hindi) in enumerate(zip(english, hindi)):\n",
        "          for t, char in enumerate(english):\n",
        "              encoder_input_data[i, t] = input_token_index[char]\n",
        "          \n",
        "          for t, char in enumerate(hindi):\n",
        "              decoder_input_data[i, t] = target_token_index[char]       \n",
        "          decoder_input_data[i, t+1:] = target_token_index[' ']\n",
        "\n",
        "      return encoder_input_data, decoder_input_data"
      ],
      "metadata": {
        "id": "EuiYz61lOhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDictionary(input_tokens, target_tokens):\n",
        "    #making a dictionary to map the characters with the indices\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_tokens)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_tokens)])\n",
        "    \n",
        "    #making a dictionary to map the indices with the characters\n",
        "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "    reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "    return input_token_index,target_token_index,reverse_input_char_index,reverse_target_char_index"
      ],
      "metadata": {
        "id": "ojQyJjfdOhxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the training words as an array from train data\n",
        "train_hindi_words, train_english_words =getWords(train_path)\n",
        "#get validation words\n",
        "val_hindi_words, val_english_words =getWords(val_path)\n",
        "#get test words\n",
        "test_hindi_words, test_english_words =getWords(test_path)\n",
        "\n",
        "  \n",
        "#get the characters from train and val and test dataset\n",
        "train_eng_characters, train_num_encoder_tokens, train_max_enc_len = getChar(train_english_words)\n",
        "train_hin_characters, train_num_decoder_tokens, train_max_dec_len = getChar(train_hindi_words)\n",
        "\n",
        "val_eng_characters, val_num_encoder_tokens, val_max_enc_len = getChar(val_english_words)\n",
        "val_hin_characters, val_num_decoder_tokens, val_max_dec_len = getChar(val_hindi_words)\n",
        "\n",
        "test_eng_characters, test_num_encoder_tokens, test_max_enc_len = getChar(test_english_words)\n",
        "test_hin_characters, test_num_decoder_tokens, test_max_dec_len = getChar(test_hindi_words)\n",
        "\n",
        "#take the largest number of tokens and max_length of words on both encoder and decoder\n",
        "num_encoder_tokens = max(val_num_encoder_tokens, train_num_encoder_tokens,test_num_encoder_tokens)\n",
        "num_decoder_tokens = max(val_num_decoder_tokens, train_num_decoder_tokens,test_num_decoder_tokens)\n",
        "\n",
        "max_enc_len = max(train_max_enc_len, val_max_enc_len,test_max_enc_len)\n",
        "max_dec_len = max(train_max_dec_len, val_max_dec_len,test_max_dec_len)\n",
        "\n",
        "#finding the set having unique characters from train, val,test data\n",
        "input_hin_characters=set()\n",
        "for char in train_hin_characters:\n",
        "  input_hin_characters.add(char)\n",
        "        \n",
        "for char in val_hin_characters:\n",
        "  input_hin_characters.add(char)\n",
        "        \n",
        "for char in test_hin_characters:\n",
        "  input_hin_characters.add(char)\n",
        "        \n",
        "\n",
        "# calling createDictionary function to make a dictionary and reverse dictionary to map the characters with the indices and indices to characters\n",
        "input_token_index,target_token_index,reverse_input_char_index,reverse_target_char_index=createDictionary(train_eng_characters,list(input_hin_characters)) \n",
        "\n",
        "#creating input data for encoder and decoder to process in batch\n",
        "train_encoder_input_data, train_decoder_input_data = getData(train_english_words, train_hindi_words, max_enc_len, max_dec_len, num_decoder_tokens, input_token_index, target_token_index)\n",
        "val_encoder_input_data, val_decoder_input_data = getData(val_english_words, val_hindi_words, max_enc_len, max_dec_len, num_decoder_tokens, input_token_index, target_token_index)\n",
        "test_encoder_input_data, test_decoder_input_data = getData(test_english_words, test_hindi_words, max_enc_len, max_dec_len, num_decoder_tokens, input_token_index, target_token_index)\n",
        "\n",
        "# converting to tensors from numpy\n",
        "train_encoder_input_data=torch.from_numpy(train_encoder_input_data).to(device).long()\n",
        "train_decoder_input_data=torch.from_numpy(train_decoder_input_data).to(device).long()\n",
        "\n",
        "val_encoder_input_data=torch.from_numpy(val_encoder_input_data).to(device).long()\n",
        "val_decoder_input_data=torch.from_numpy(val_decoder_input_data).to(device).long()\n",
        "\n",
        "test_encoder_input_data=torch.from_numpy(test_encoder_input_data).to(device).long()\n",
        "test_decoder_input_data=torch.from_numpy(test_decoder_input_data).to(device).long()\n"
      ],
      "metadata": {
        "id": "lsOA5hE8Ohum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Encoder Part**"
      ],
      "metadata": {
        "id": "Jdu6HP9pO4Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,cell,embedding_size,hidden_size,no_of_layers,dropout):\n",
        "        super(Encoder,self).__init__()\n",
        "        #setting the encoder part\n",
        "        self.hidden_size=hidden_size\n",
        "        self.input_token_index_len=len(input_token_index)\n",
        "        self.no_of_layers = no_of_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        self.cell=cell\n",
        "        self.train_eng_characters=train_eng_characters\n",
        "        self.drop = nn.Dropout(dropout) # using dropout\n",
        "        #creating an embedding layer\n",
        "        self.encoder_embedding = nn.Embedding(self.input_token_index_len,self.embedding_size).to(device)\n",
        "        self.gru = nn.GRU(self.embedding_size,self.hidden_size,self.no_of_layers,batch_first = True,bidirectional = True).to(device)\n",
        "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.no_of_layers,batch_first = True,bidirectional = True).to(device)\n",
        "        self.lstm = nn.LSTM(self.embedding_size,self.hidden_size,self.no_of_layers,batch_first = True,bidirectional = True).to(device)\n",
        "    \n",
        "    #forward function for encoder\n",
        "    def forward(self,input,hidden,cell):\n",
        "        enc_embedd= self.encoder_embedding(input)\n",
        "        temp=enc_embedd\n",
        "        #using dropout\n",
        "        enc_embedd = self.drop(temp)\n",
        "        # RNN/GRU/LSTM layer of the encoder\n",
        "        if(self.cell == 'RNN'):\n",
        "            input1=enc_embedd\n",
        "            input2=hidden\n",
        "            output,hidden = self.rnn(input1,input2)\n",
        "        elif(self.cell == 'GRU'):\n",
        "            input1=enc_embedd\n",
        "            input2=hidden\n",
        "            output,hidden = self.gru(input1,input2)\n",
        "        elif(self.cell == 'LSTM'):\n",
        "            input1=enc_embedd\n",
        "            output,(hidden,cell) = self.lstm(input1,(hidden,cell))\n",
        "        return output,(hidden,cell)"
      ],
      "metadata": {
        "id": "-ULn_CaOOhru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decoder Part**"
      ],
      "metadata": {
        "id": "bU-9PZCgO-fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,cell,embedding_size,hidden_size,no_of_layers,dropout,batchsize):\n",
        "        super(Decoder,self).__init__()\n",
        "        #setting the encoder part\n",
        "        self.cell=cell\n",
        "        self.no_of_layers = no_of_layers\n",
        "        self.target_token_index_len=len(target_token_index)\n",
        "        self.drop = nn.Dropout(dropout)  #using dropout\n",
        "        self.embedding_size = embedding_size\n",
        "        self.train_hin_characters=train_hin_characters\n",
        "        self.hidden_size=hidden_size\n",
        "        self.batchsize=batchsize\n",
        "        #creating an embedding layer\n",
        "        self.decoder_embedding = nn.Embedding(self.target_token_index_len,self.embedding_size).to(device)\n",
        "        input1=embedding_size+ hidden_size*2\n",
        "        self.lstm = nn.LSTM(input1,hidden_size,self.no_of_layers,batch_first = True).to(device)\n",
        "        input2=embedding_size + hidden_size*2\n",
        "        self.rnn = nn.RNN(input2,hidden_size,self.no_of_layers,batch_first = True).to(device)\n",
        "        input3=embedding_size+ hidden_size*2\n",
        "        self.gru = nn.GRU(input3,hidden_size,self.no_of_layers,batch_first = True).to(device)\n",
        "        input4=self.target_token_index_len\n",
        "        self.linear = nn.Linear(self.hidden_size,input4,bias=True).to(device)\n",
        "        self.softmax = nn.Softmax(dim = 2).to(device)\n",
        "\n",
        "    #using forward function for decoder\n",
        "    def forward(self,input,hidden,cell,hiddenj):\n",
        "        dec_embedd = self.decoder_embedding(input)\n",
        "        temp1=hiddenj[0].reshape(self.batchsize,1,self.hidden_size)\n",
        "        temp2=hiddenj[1].reshape(self.batchsize,1,self.hidden_size)\n",
        "        dec_embedd=torch.cat((dec_embedd,temp1,temp2),dim=2)\n",
        "        dec_embedd=self.drop(dec_embedd)\n",
        "        # RNN/GRU/LSTM layer of the decoder\n",
        "        if(self.cell == 'LSTM'):\n",
        "            input1=dec_embedd\n",
        "            output,(hidden,cell) = self.lstm(dec_embedd,(hidden,cell))\n",
        "        elif(self.cell == 'RNN'):\n",
        "            input1=dec_embedd\n",
        "            input2=hidden\n",
        "            output,hidden = self.rnn(input1,input2)\n",
        "        elif(self.cell == 'GRU'):\n",
        "            input1=dec_embedd\n",
        "            input2=hidden\n",
        "            output,hidden = self.gru(input1,input2)\n",
        "        output = self.linear(output)\n",
        "        temp=(hidden,cell)\n",
        "        return output,temp"
      ],
      "metadata": {
        "id": "HoPlFOvpOhpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Helper Functions**"
      ],
      "metadata": {
        "id": "U8vtjxa1i1TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get batchsize of data\n",
        "def getBatchData(input,batchsize,x):\n",
        "  return input[x:x+batchsize]\n",
        "\n",
        "# function to do split as output is also biredictional output as encoder is bidirectional. So we are splitting it.\n",
        "def getSplit(output,hidden_size):\n",
        "  temp=torch.split(output,[hidden_size,hidden_size],dim = 2)\n",
        "  input1=temp[0]\n",
        "  input2=temp[1]\n",
        "  temp=torch.add(input1,input2)/2\n",
        "  return temp\n",
        "  \n",
        "# function to do resize as encoder is bidirectional asnd decoder is unidirectional. so we are reshaping it.\n",
        "def getResize(var,val,no_of_layers,batchsize,hidden_size):\n",
        "  var=var.reshape(2,no_of_layers,batchsize,hidden_size)\n",
        "  var=torch.add(var[0],var[1])/2\n",
        "  return var\n",
        "\n",
        "#function to concatenate and return as tuple\n",
        "def getConcatenation(lst):\n",
        "  temp= torch.cat(tuple(x for x in lst),dim =1).to(device)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "UN8JRnLxPDUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate accuracy\n",
        "def getAccuracy(target,output):\n",
        "    n=len(target)\n",
        "    total = 0\n",
        "    i=0\n",
        "    while i<n:\n",
        "        if(torch.equal(target[i],output[i])):\n",
        "            total += 1\n",
        "        i+=1\n",
        "    return total"
      ],
      "metadata": {
        "id": "QfB_3n-TPNxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Function for validation data**"
      ],
      "metadata": {
        "id": "xIfk6bHNUTJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getValidation(attention,val_encoder_input_data,val_decoder_input_data,encoder,decoder,batchsize,hidden_size,embedding_size,no_of_layers):\n",
        "    with torch.no_grad():\n",
        "        temp=torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n",
        "        enc_hidden = temp\n",
        "        enc_cell = temp\n",
        "        total_loss=0\n",
        "        total_acc=0\n",
        "        for x in range(0,len(val_encoder_input_data),batchsize):\n",
        "            y_pred=[]\n",
        "            y_actual=[]\n",
        "            loss=0\n",
        "            #input for encoder\n",
        "            input_tensor = getBatchData(val_encoder_input_data,batchsize,x).to(device)\n",
        "            #calling encoder forward function\n",
        "            output,(hidden,cell) = encoder.forward(input_tensor,enc_hidden,enc_cell)\n",
        "            output = getSplit(output,hidden_size)\n",
        "            #input for first hidden state in decoder\n",
        "            input =val_decoder_input_data[x:x+batchsize,0].to(device).reshape(batchsize,1)\n",
        "            #calling resize because encoder is bidirectional\n",
        "            hidden = getResize(hidden,2,no_of_layers,batchsize,hidden_size)\n",
        "            cell = getResize(cell,2,no_of_layers,batchsize,hidden_size)\n",
        "            hiddenj = hidden\n",
        "            k=0\n",
        "            temp1=output if attention else hiddenj\n",
        "            #ruuning while loop for max no of characters in decoder data\n",
        "            while k<max_dec_len:\n",
        "                output1,(hidden,cell) = decoder.forward(input,hidden,cell,temp1)\n",
        "                output2 = decoder.softmax(output1)\n",
        "                output3 = torch.argmax(output2,dim = 2)\n",
        "                y_pred.append(output1) # storing decoder predicted value\n",
        "                y_actual.append(output3)# storing decoder predicted value index\n",
        "                input = output3\n",
        "                k+=1\n",
        "            #flattening the tensor\n",
        "            y_pred = getConcatenation(y_pred).reshape(max_dec_len*batchsize,len(target_token_index))\n",
        "            y_actual = getConcatenation(y_actual)\n",
        "            var=val_decoder_input_data[x:x+batchsize]\n",
        "            total_acc += getAccuracy(var.to(device),y_actual) #calling accuracy function to get accuracy\n",
        "            #calculating loss\n",
        "            loss  = nn.CrossEntropyLoss(reduction = 'sum')(y_pred,var.reshape(-1).to(device))\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "        denom=(len(val_decoder_input_data)*max_dec_len)\n",
        "        val_loss = total_loss/denom  # calculating val loss\n",
        "        total_loss=0\n",
        "        #calculating val accuracy\n",
        "        val_accuracy = (total_acc/len(val_decoder_input_data))\n",
        "        val_accuracy=val_accuracy*100\n",
        "        total_acc=0\n",
        "        return val_loss,val_accuracy"
      ],
      "metadata": {
        "id": "JrynLImkUN87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Function**"
      ],
      "metadata": {
        "id": "Y312AlwRPyYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(rnn,batchsize,hidden_size,embedding_size,no_of_layers,dropout,epochs):\n",
        "    teacher_ratio = 0.5\n",
        "    total_loss=0\n",
        "    total_acc=0\n",
        "    learning_rate=0.001\n",
        "    #creating encoder and decoder model\n",
        "    encoder = Encoder(rnn,embedding_size,hidden_size,no_of_layers,dropout).to(device)\n",
        "    decoder = Decoder(rnn,embedding_size,hidden_size,no_of_layers,dropout,batchsize).to(device)\n",
        "    opt_encoder = optim.Adam(encoder.parameters(),learning_rate)\n",
        "    opt_decoder  = optim.Adam(decoder.parameters(),learning_rate)\n",
        "    loss=0\n",
        "    #running for loop epochs no of times\n",
        "    for i in range(epochs):\n",
        "        print('Epoch---',i+1,end=\" \")\n",
        "        #getting batchsize amount of encoder data\n",
        "        for x in range(0,len(train_encoder_input_data),batchsize):\n",
        "            y_pred = [] # to store predicted value by decoder to calculate loss\n",
        "            y_val = []  #to store index of predicted value by decoder to calculate accuracy\n",
        "            hidden_input = torch.zeros(no_of_layers,batchsize,hidden_size).to(device) # initial input to first hidden state(S0)\n",
        "            temp=torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n",
        "            input_tensor = getBatchData(train_encoder_input_data,batchsize,x).to(device) # to get batchsize of train data for encoder\n",
        "            input_tensor_size=input_tensor.size()[0]\n",
        "            #initializing with zeroes\n",
        "            enc_hidden =temp\n",
        "            enc_cell = temp\n",
        "            if(batchsize>input_tensor_size):\n",
        "              break\n",
        "            #calling forward function of encoder\n",
        "            output,(hidden,cell) = encoder.forward(input_tensor,enc_hidden,enc_cell)\n",
        "            input = train_decoder_input_data[x:x+batchsize,0].to(device).reshape(batchsize,1) # to get batchsize amount of decoder input data for first hidden state\n",
        "            #doing the resizeing for bidirectional implementation\n",
        "            hidden = doResize(hidden,2,no_of_layers,batchsize,hidden_size)\n",
        "            cell = doResize(cell,2,no_of_layers,batchsize,hidden_size)\n",
        "            hiddenj = hidden\n",
        "            #using teacher forcing \n",
        "            teacher_forcing = True if random.random() < teacher_ratio else False\n",
        "            k=0\n",
        "            if teacher_forcing:\n",
        "                #runing while loop for max no of characters in decoder data\n",
        "                while k<max_dec_len:\n",
        "                    output1,(hidden,cell) = decoder.forward(input,hidden,cell,hiddenj) # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2,dim = 2)\n",
        "                    y_pred.append(output1) # storing decoder predicted value\n",
        "                    y_val.append(output3) # storing decoder predicted value index\n",
        "                    input = train_decoder_input_data[x:x+batchsize,i].to(device).reshape(batchsize,1) # giving groung truth data for next input\n",
        "                    k+=1\n",
        "            else:\n",
        "                while k<max_dec_len:\n",
        "                    output1,(hidden,cell) = decoder.forward(input,hidden,cell,hiddenj)  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2,dim = 2)\n",
        "                    y_pred.append(output1)  # storing decoder predicted value\n",
        "                    y_val.append(output3)   # storing decoder predicted value index\n",
        "                    input = output3  # giving last output as next input\n",
        "                    k+=1\n",
        "            #flattening the tensor     \n",
        "            y_pred = getConcatenation(y_pred).to(device).reshape(max_dec_len*batchsize,len(target_token_index)) # \n",
        "            y_val = getConcatenation(y_val)\n",
        "            var=getBatchData(train_decoder_input_data,batchsize,x)\n",
        "            total_acc += getAccuracy(var.to(device),y_val) #calling accuracy function to get accuracy\n",
        "            #calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction = 'sum')(y_pred,var.reshape(-1).to(device))\n",
        "            with torch.no_grad():\n",
        "              total_loss += loss.item()\n",
        "            loss.backward(retain_graph = True)\n",
        "            #clipping the gradient\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n",
        "            opt_encoder.step()\n",
        "            opt_decoder.step()\n",
        "            opt_encoder.zero_grad()\n",
        "            opt_decoder.zero_grad()\n",
        "            loss=0\n",
        "        del(y_pred)\n",
        "        del(y_val)\n",
        "        del(input)\n",
        "        del(output1)\n",
        "        del(output2)\n",
        "        del(output3)\n",
        "        del(hidden)\n",
        "        del(cell)\n",
        "        del(hiddenj)\n",
        "        del(output)\n",
        "        denom=(len(train_decoder_input_data)*max_dec_len)\n",
        "        training_loss = total_loss/denom # calculating training loss\n",
        "        #calculating training accuracy\n",
        "        training_accuracy = (total_acc/len(train_decoder_input_data))*100\n",
        "        #calling getValidation to get validation loss and accuracy\n",
        "        validation_loss,validation_accuracy = getValidation(False,val_encoder_input_data,val_decoder_input_data,encoder,decoder,batchsize,hidden_size,embedding_size,no_of_layers)\n",
        "        print(' Train loss = ',training_loss,' Train accuracy = ',training_accuracy,'   validation loss= ',validation_loss,'  validation accuaracy= ',validation_accuracy)\n",
        "        total_loss=0\n",
        "        total_acc=0"
      ],
      "metadata": {
        "id": "OEseFzv2PRME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for sweep without attention\n",
        "def vanilla():\n",
        "    wandb.init(project='DL-Assignment3')\n",
        "    config = wandb.config\n",
        "    wandb.run.name = \"withoutattention_cell_type_{}_bidirec_{}_layers_{}_batchsize_{}_hidden_{}\".format(config.cell_type,config.bidirectional,config.no_of_layers,config.batchsize,config.hidden_size)\n",
        "    epochs = config.epochs\n",
        "    gpu_usage()  \n",
        "    hidden_size = config.hidden_size\n",
        "    embedding_size = config.input_embedding_size\n",
        "    dropout = config.dropout\n",
        "    gpu_usage()\n",
        "    no_of_layers = config.no_of_layers\n",
        "    batchsize = config.batchsize\n",
        "    rnn = config.cell_type\n",
        "    #calling train function\n",
        "    Encoder1,Decoder1 = train(rnn,batchsize,hidden_size,embedding_size,no_of_layers,dropout,epochs)\n",
        "    gpu_usage()                             \n",
        "    torch.cuda.empty_cache()\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "    gpu_usage()"
      ],
      "metadata": {
        "id": "dVrGLuoYXBjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration = {\n",
        "    'method' : 'bayes',\n",
        "    'metric' : { 'goal' : 'maximize',\n",
        "    'name' : 'validation_accuracy'},\n",
        "    'parameters':{\n",
        "        'cell_type' : {'values' : ['LSTM','RNN','GRU']},\n",
        "        'batchsize' : {'values' : [128,256]},\n",
        "        'input_embedding_size' : {'values' : [128,256,512,1024]},\n",
        "        'dropout' : {'values' : [0.1,0.2,0.3,0.4,0.5]},\n",
        "        'no_of_layers' : {'values' : [2,3,4]},\n",
        "        'hidden_size' : {'values' : [128,256,512,1024]},\n",
        "        'bidirectional' : {'values' : ['Yes']},\n",
        "        'epochs' : {'values' : [10,20,30]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep = sweep_configuration,project = 'DL-Assignment3')\n",
        "wandb.agent(sweep_id,function=vanilla,count = 10)"
      ],
      "metadata": {
        "id": "UH39uOrSXAN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}