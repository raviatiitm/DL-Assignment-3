{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jYPFwHOUaO"
      },
      "outputs": [],
      "source": [
        "# getting data files path\n",
        "train_path = \"/content/hin_train.csv\"\n",
        "val_path = \"/content/hin_valid.csv\"\n",
        "test_path = \"/content/hin_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNh8EaeDOh7a"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import torchvision\n",
        "import zipfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax135O61Y7mO",
        "outputId": "af569cc3-bb14-48a2-a0b8-7790f050de69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=765c0da680ebab9c9a99b949714d3404d54fa0c22077bf6c0bd14a2e12f14982\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7urLxX9Y-S3"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "421IwO8nZBqU",
        "outputId": "9df25bfe-8b18-45f6-b5cb-57481929a040"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yvtseS8ZKLk",
        "outputId": "aec75bac-d681-4737-a6ef-3ad6a5e4ad64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=0d3f69c2b1e6fe1ca99130ab8ee8c243b879da39bc6a2f484a385f4fd986bfca\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil\n",
        "import torch\n",
        "from numba import cuda\n",
        "from GPUtil import showUtilization as gpu_usage"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HIrs9IvNOlu1"
      },
      "source": [
        "## **Data PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAAo52mZOh4p"
      },
      "outputs": [],
      "source": [
        "def getWords(path):\n",
        "    hindi = []\n",
        "    english = []\n",
        "\n",
        "    file = open(path)\n",
        "    dataset = csv.reader(file, delimiter=\",\")\n",
        "\n",
        "    # to get the words in a list\n",
        "\n",
        "    for data in dataset:\n",
        "        e = data[0]\n",
        "        h = data[1]\n",
        "        english.append(e)\n",
        "        hindi.append(h)\n",
        "\n",
        "    # appending the start and end characters to hindi words\n",
        "    for i in range(len(hindi)):\n",
        "        hindi[i] = \"\\t\" + hindi[i] + \"\\n\"\n",
        "\n",
        "    return np.array(hindi), np.array(english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDRd7_AXOh2F"
      },
      "outputs": [],
      "source": [
        "def getChar(data):\n",
        "    data_char = set()  # to store the the unique characters present in data\n",
        "    data_char.add(\" \")\n",
        "    for word in data:\n",
        "        for char in word:\n",
        "            if char not in data_char:\n",
        "                data_char.add(char)\n",
        "\n",
        "    # sort the characters in dataset\n",
        "    data_char = sorted(list(data_char))\n",
        "\n",
        "    # number of characters in the set\n",
        "    num_tokens = len(data_char)\n",
        "\n",
        "    # get the max length of the words\n",
        "    max_len = max([len(word) for word in data])\n",
        "\n",
        "    # return set of all characters in data\n",
        "    return data_char, num_tokens, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuiYz61lOhzk"
      },
      "outputs": [],
      "source": [
        "def getData(\n",
        "    english,\n",
        "    hindi,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        "):\n",
        "    # initializing with 0s for max_length\n",
        "    encoder_input_data = np.zeros((len(english), max_enc_len), dtype=\"float32\")\n",
        "    decoder_input_data = np.zeros((len(english), max_dec_len), dtype=\"float32\")\n",
        "\n",
        "    # creating indices for characters that exist\n",
        "    for i, (english, hindi) in enumerate(zip(english, hindi)):\n",
        "        for t, char in enumerate(english):\n",
        "            encoder_input_data[i, t] = input_token_index[char]\n",
        "\n",
        "        for t, char in enumerate(hindi):\n",
        "            decoder_input_data[i, t] = target_token_index[char]\n",
        "        decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "\n",
        "    return encoder_input_data, decoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojQyJjfdOhxO"
      },
      "outputs": [],
      "source": [
        "def createDictionary(input_tokens, target_tokens):\n",
        "    # making a dictionary to map the characters with the indices\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_tokens)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_tokens)])\n",
        "\n",
        "    # making a dictionary to map the indices with the characters\n",
        "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "    reverse_target_char_index = dict(\n",
        "        (i, char) for char, i in target_token_index.items()\n",
        "    )\n",
        "    return (\n",
        "        input_token_index,\n",
        "        target_token_index,\n",
        "        reverse_input_char_index,\n",
        "        reverse_target_char_index,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsOA5hE8Ohum"
      },
      "outputs": [],
      "source": [
        "# get the training words as an array from train data\n",
        "train_hindi_words, train_english_words = getWords(train_path)\n",
        "# get validation words\n",
        "val_hindi_words, val_english_words = getWords(val_path)\n",
        "# get test words\n",
        "test_hindi_words, test_english_words = getWords(test_path)\n",
        "\n",
        "# get the characters from train and val and test dataset\n",
        "train_eng_characters, train_num_encoder_tokens, train_max_enc_len = getChar(\n",
        "    train_english_words\n",
        ")\n",
        "train_hin_characters, train_num_decoder_tokens, train_max_dec_len = getChar(\n",
        "    train_hindi_words\n",
        ")\n",
        "\n",
        "val_eng_characters, val_num_encoder_tokens, val_max_enc_len = getChar(val_english_words)\n",
        "val_hin_characters, val_num_decoder_tokens, val_max_dec_len = getChar(val_hindi_words)\n",
        "\n",
        "test_eng_characters, test_num_encoder_tokens, test_max_enc_len = getChar(\n",
        "    test_english_words\n",
        ")\n",
        "test_hin_characters, test_num_decoder_tokens, test_max_dec_len = getChar(\n",
        "    test_hindi_words\n",
        ")\n",
        "\n",
        "# take the largest number of tokens and max_length of words on both encoder and decoder\n",
        "num_encoder_tokens = max(\n",
        "    val_num_encoder_tokens, train_num_encoder_tokens, test_num_encoder_tokens\n",
        ")\n",
        "num_decoder_tokens = max(\n",
        "    val_num_decoder_tokens, train_num_decoder_tokens, test_num_decoder_tokens\n",
        ")\n",
        "\n",
        "max_enc_len = max(train_max_enc_len, val_max_enc_len, test_max_enc_len)\n",
        "max_dec_len = max(train_max_dec_len, val_max_dec_len, test_max_dec_len)\n",
        "\n",
        "# finding the set having unique characters from train, val,test data\n",
        "input_hin_characters = set()\n",
        "for char in train_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "for char in val_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "for char in test_hin_characters:\n",
        "    input_hin_characters.add(char)\n",
        "\n",
        "\n",
        "# calling createDictionary function to make a dictionary and reverse dictionary to map the characters with the indices and indices to characters\n",
        "(\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        "    reverse_input_char_index,\n",
        "    reverse_target_char_index,\n",
        ") = createDictionary(train_eng_characters, list(input_hin_characters))\n",
        "\n",
        "# creating input data for encoder and decoder to process in batch\n",
        "train_encoder_input_data, train_decoder_input_data = getData(\n",
        "    train_english_words,\n",
        "    train_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "val_encoder_input_data, val_decoder_input_data = getData(\n",
        "    val_english_words,\n",
        "    val_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "test_encoder_input_data, test_decoder_input_data = getData(\n",
        "    test_english_words,\n",
        "    test_hindi_words,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    num_decoder_tokens,\n",
        "    input_token_index,\n",
        "    target_token_index,\n",
        ")\n",
        "\n",
        "# converting to tensors from numpy\n",
        "train_encoder_input_data = torch.from_numpy(train_encoder_input_data).to(device).long()\n",
        "train_decoder_input_data = torch.from_numpy(train_decoder_input_data).to(device).long()\n",
        "\n",
        "val_encoder_input_data = torch.from_numpy(val_encoder_input_data).to(device).long()\n",
        "val_decoder_input_data = torch.from_numpy(val_decoder_input_data).to(device).long()\n",
        "\n",
        "test_encoder_input_data = torch.from_numpy(test_encoder_input_data).to(device).long()\n",
        "test_decoder_input_data = torch.from_numpy(test_decoder_input_data).to(device).long()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdu6HP9pO4Ql"
      },
      "source": [
        "##**Encoder Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ULn_CaOOhru"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, cell, embedding_size, hidden_size, no_of_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        # setting the encoder part\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_token_index_len = len(input_token_index)\n",
        "        self.no_of_layers = no_of_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        self.cell = cell\n",
        "        self.train_eng_characters = train_eng_characters\n",
        "        self.drop = nn.Dropout(dropout)  # using dropout\n",
        "        # creating an embedding layer\n",
        "        self.encoder_embedding = nn.Embedding(\n",
        "            self.input_token_index_len, self.embedding_size\n",
        "        ).to(device)\n",
        "        self.gru = nn.GRU(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "        self.rnn = nn.RNN(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "        self.lstm = nn.LSTM(\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            self.no_of_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        ).to(device)\n",
        "\n",
        "    # forward function for encoder\n",
        "    def forward(self, input, hidden, cell):\n",
        "        enc_embedd = self.encoder_embedding(input)\n",
        "        temp = enc_embedd\n",
        "        # using dropout\n",
        "        enc_embedd = self.drop(temp)\n",
        "        # RNN/GRU/LSTM layer of the encoder\n",
        "        if self.cell == \"RNN\":\n",
        "            input1 = enc_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.rnn(input1, input2)\n",
        "        elif self.cell == \"GRU\":\n",
        "            input1 = enc_embedd\n",
        "            input2 = hidden\n",
        "            output, hidden = self.gru(input1, input2)\n",
        "        elif self.cell == \"LSTM\":\n",
        "            input1 = enc_embedd\n",
        "            output, (hidden, cell) = self.lstm(input1, (hidden, cell))\n",
        "        return output, (hidden, cell)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bU-9PZCgO-fs"
      },
      "source": [
        "## **Decoder Attention Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoPlFOvpOhpG"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self, cell, embedding_size, hidden_size, no_of_layers, dropout, batchsize\n",
        "    ):\n",
        "        super(Attention, self).__init__()\n",
        "        self.layer = no_of_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batchsize = batchsize\n",
        "        self.cell = cell\n",
        "        self.embedding = nn.Embedding(target_token_index_len, embedding_size).to(device)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        # calculating lstm model\n",
        "        input1 = embedding_size + hidden_size\n",
        "        self.LSTM = nn.LSTM(input1, hidden_size, self.layer, batch_first=True).to(\n",
        "            device\n",
        "        )\n",
        "        input2 = embedding_size + hidden_size\n",
        "        self.GRU = nn.GRU(input2, hidden_size, self.layer, batch_first=True).to(device)\n",
        "        input3 = embedding_size + hidden_size\n",
        "        self.RNN = nn.RNN(input3, hidden_size, self.layer, batch_first=True).to(device)\n",
        "        temp = 1\n",
        "        self.V = nn.Linear(hidden_size, temp, bias=False).to(device)\n",
        "        temp = hidden_size\n",
        "        self.U = nn.Linear(hidden_size, temp, bias=False).to(device)\n",
        "        temp = hidden_size\n",
        "        self.W = nn.Linear(hidden_size, temp, bias=False).to(device)\n",
        "        temp = target_token_index_len\n",
        "        self.linear = nn.Linear(hidden_size, temp, bias=True).to(device)\n",
        "        self.softmax = nn.Softmax(dim=2).to(device)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        ct = torch.zeros(self.batchsize, 1, self.hidden_size).to(device)\n",
        "        Wh = self.W(hidden[-1]).reshape_(self.batchsize, 1, self.hidden_size)\n",
        "        Us = self.U(encoder_outputs)\n",
        "        temp = Us + Wh\n",
        "        ejt = self.V(torch.tanh(temp))\n",
        "        alphajt = nn.Softmax(dim=1)(ejt)\n",
        "        embedded = self.embedding(input)\n",
        "        ct = torch.bmm(alphajt.transpose(1, 2), encoder_outputs)\n",
        "        new_input = torch.cat((embedded, ct), dim=2)\n",
        "        if self.rnn == \"LSTM\":\n",
        "            input1 = new_input\n",
        "            input2 = (hidden, cell)\n",
        "            output, (hidden, cell) = self.LSTM(input1, input2)\n",
        "        elif self.rnn == \"RNN\":\n",
        "            input1 = new_input\n",
        "            input2 = hidden\n",
        "            output, hidden = self.RNN(input1, input2)\n",
        "        elif self.rnn == \"GRU\":\n",
        "            input1 = new_input\n",
        "            input2 = hidden\n",
        "            output, hidden = self.GRU(input1, input2)\n",
        "        output = self.linear(output)\n",
        "        temp = (hidden, cell)\n",
        "        return output, temp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U8vtjxa1i1TU"
      },
      "source": [
        "## **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN8JRnLxPDUt"
      },
      "outputs": [],
      "source": [
        "# function to get batchsize of data\n",
        "def getBatchData(input, batchsize, x):\n",
        "    return input[x : x + batchsize]\n",
        "\n",
        "\n",
        "# function to do split as output is also biredictional output as encoder is bidirectional. So we are splitting it.\n",
        "def getSplit(output, hidden_size):\n",
        "    temp = torch.split(output, [hidden_size, hidden_size], dim=2)\n",
        "    input1 = temp[0]\n",
        "    input2 = temp[1]\n",
        "    temp = torch.add(input1, input2) / 2\n",
        "    return temp\n",
        "\n",
        "\n",
        "# function to do resize as encoder is bidirectional asnd decoder is unidirectional. so we are reshaping it.\n",
        "def getResize(var, val, no_of_layers, batchsize, hidden_size):\n",
        "    var = var.reshape(2, no_of_layers, batchsize, hidden_size)\n",
        "    var = torch.add(var[0], var[1]) / 2\n",
        "    return var\n",
        "\n",
        "\n",
        "# function to concatenate and return as tuple\n",
        "def getConcatenation(lst):\n",
        "    temp = torch.cat(tuple(x for x in lst), dim=1).to(device)\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfB_3n-TPNxS"
      },
      "outputs": [],
      "source": [
        "# function to calculate accuracy\n",
        "def getAccuracy(target, output):\n",
        "    n = len(target)\n",
        "    total = 0\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        if torch.equal(target[i], output[i]):\n",
        "            total += 1\n",
        "        i += 1\n",
        "    return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vk3jht5OBK0"
      },
      "outputs": [],
      "source": [
        "# getList function to process the attention maatrix for heat map plot\n",
        "def getList(attn_matrix, x, batchsize):\n",
        "    output1 = torch.cat(tuple(x for x in attn_matrix), dim=2).to(device)\n",
        "    temp1 = test_english_words[x : x + batchsize][x]\n",
        "    temp2 = test_hindi_words[x : x + batchsize][x]\n",
        "    len_english = len(temp1) + 1\n",
        "    len_hindi = len(temp2) + 1\n",
        "    list_y = [ele for ele in temp1]\n",
        "    list_x = [ele for ele in temp2]\n",
        "    return output1, len_english, len_hindi, list_y, list_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mRFMiD5OFzM"
      },
      "outputs": [],
      "source": [
        "# function to craete attention heat maps\n",
        "def attentionPlot(\n",
        "    attention,\n",
        "    val_encoder_input_data,\n",
        "    val_decoder_input_data,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    batchsize,\n",
        "    hidden_size,\n",
        "    embedding_size,\n",
        "    no_of_layers,\n",
        "    matrix,\n",
        "):\n",
        "    with torch.no_grad():\n",
        "        temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "        # initializing with zeroes\n",
        "        enc_hidden = temp\n",
        "        enc_cell = temp\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for x in range(0, len(test_encoder_input_data), batchsize):\n",
        "            y_pred = []  # to store predicted value by decoder to calculate loss\n",
        "            y_actual = (\n",
        "                []\n",
        "            )  # to store index of predicted value by decoder to calculate accuracy\n",
        "            loss = 0\n",
        "            attn_matrix = []  # to store attention alphajt\n",
        "            input_tensor = getBatchData(test_encoder_input_data, batchsize, x).to(\n",
        "                device\n",
        "            )  # initial input to first hidden state(S0)\n",
        "            input_tensor_size = input_tensor.size()[0]\n",
        "            if batchsize > input_tensor_size:\n",
        "                break\n",
        "            # calling encoder\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            output = getSplit(output, hidden_size)\n",
        "            input = (\n",
        "                test_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )\n",
        "            # doing the resizeing for bidirectional implementation\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            k = 0\n",
        "            temp1 = output if attention else hiddenj\n",
        "            # ruuning while loop for max no of characters in decoder data\n",
        "            while k < max_dec_len:\n",
        "                if matrix:\n",
        "                    alphajt, output1, (hidden, cell) = decoder.forward(\n",
        "                        input, hidden, cell, temp1, matrix\n",
        "                    )  # calling decoder forward\n",
        "                    attn_matrix.append(alphajt)\n",
        "                else:\n",
        "                    output1, (hidden, cell) = decoder.forward(\n",
        "                        input, hidden, cell, temp1, matrix\n",
        "                    )  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    y_pred.append(output1)\n",
        "                    y_actual.append(output3)\n",
        "                    input = output3  # giving last output as next input\n",
        "                k += 1\n",
        "            # calling getList function to process the attn_matrix\n",
        "            attn_matrix, len_english, len_hindi, list_x, list_y = getList(\n",
        "                attn_matrix, x, batchsize\n",
        "            )\n",
        "            data = attn_matrix[0].resize(26, 21).cpu().numpy()\n",
        "            sns.heatmap(\n",
        "                data[1 : len_english + 1, 1 : len_hindi + 1],\n",
        "                cmap=\"viridis\",\n",
        "                ax=axes[x],\n",
        "                cbar=True,\n",
        "                cbar_kws={\"label\": \"Value\"},\n",
        "            )\n",
        "            hindi_font = FontProperties(fname=\"/content/nirmala.ttf\")\n",
        "            rows, cols = data[0:len_english, 0:len_hindi].shape\n",
        "            # code for plotting the heap map\n",
        "            axes[x].set_yticks(np.arange(rows) + 0.5)\n",
        "            axes[x].set_yticklabels(list_y)\n",
        "            axes[x].set_xticks(np.arange(cols) + 0.5)\n",
        "            axes[x].set_xticklabels(list_x, fontproperties=hindi_font)\n",
        "            cbar = axes[x].collections[0].colorbar\n",
        "            cbar.set_label(\"Value\")\n",
        "        fig.savefig(\"ex.png\")\n",
        "        temp = plt.imread(\"ex.png\")\n",
        "        plot.append(temp)\n",
        "        plt.show()\n",
        "        image = wandb.Image(plot[0])\n",
        "        wandb.log({\"attention heatmaps\": image})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYewblSyhthQ"
      },
      "outputs": [],
      "source": [
        "# function to concatenate characters\n",
        "def getword(characters):\n",
        "    return \"\".join(characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "picRtGW3fqro"
      },
      "outputs": [],
      "source": [
        "# function to get prediction vanilla\n",
        "def getPredictions(target, output, df):\n",
        "    l = len(df)\n",
        "    n = len(output)\n",
        "    k = 0\n",
        "    while k < n:\n",
        "        y_org = []\n",
        "        y_pred = []\n",
        "        for y in target[k]:\n",
        "            if y == 1:\n",
        "                break\n",
        "            else:\n",
        "                y_org.append(y)\n",
        "        for y in output[k]:\n",
        "            if y == 1:\n",
        "                break\n",
        "            else:\n",
        "                y_pred.append(y)\n",
        "        df.loc[l, [\"True\"]] = getword(\n",
        "            [reverse_target_char_index[k.item()] for x in y_org]\n",
        "        )\n",
        "        df.loc[l, [\"Predicted\"]] = getword(\n",
        "            [reverse_target_char_index[k.item()] for x in y_pred]\n",
        "        )\n",
        "        l += 1\n",
        "        k += 1\n",
        "    return df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xIfk6bHNUTJk"
      },
      "source": [
        "## **Function for Test data Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n_McD4cecKA"
      },
      "outputs": [],
      "source": [
        "def Evaluate(\n",
        "    attention,\n",
        "    test_encoder_input_data,\n",
        "    test_decoder_input_data,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    batchsize,\n",
        "    hidden_size,\n",
        "    embedding_size,\n",
        "    no_of_layers,\n",
        "):\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        # initializing with 0's\n",
        "        temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "        enc_hidden = temp\n",
        "        enc_cell = temp\n",
        "        df = pd.DataFrame()  # getiing empty pandas dataframe\n",
        "        for x in range(0, len(test_encoder_input_data), batchsize):\n",
        "            loss = 0\n",
        "            y_pred = []  # to store predicted value by decoder to calculate loss\n",
        "            y_actual = (\n",
        "                []\n",
        "            )  # to store index of predicted value by decoder to calculate accuracy\n",
        "            input_tensor = getBatchData(test_encoder_input_data, batchsize, x).to(\n",
        "                device\n",
        "            )  # initial input to first hidden state(S0)\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            output = getSplit(output, hidden_size)\n",
        "            input = (\n",
        "                test_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )  # to get batchsize of train data for encoder\n",
        "            # calling resize because encoder is bidirectional\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            temp1 = output if attention else hiddenj\n",
        "            k = 0\n",
        "            # runing while loop for max no of characters in decoder data\n",
        "            while k < max_dec_len:\n",
        "                output1, (hidden, cell) = decoder.forward(input, hidden, cell, temp1)\n",
        "                output2 = decoder.softmax(output1)\n",
        "                output3 = torch.argmax(output2, dim=2)\n",
        "                y_pred.append(output1)  # storing decoder predicted value\n",
        "                y_actual.append(output3)  # storing decoder predicted value index\n",
        "                input = output3\n",
        "                k += 1\n",
        "            # flattening the tensor\n",
        "            y_pred = getConcatenation(y_pred).reshape(\n",
        "                max_dec_len * batchsize, len(target_token_index)\n",
        "            )\n",
        "            y_actual = getConcatenation(y_actual)\n",
        "            var = test_decoder_input_data[x : x + batchsize]\n",
        "            total_acc += getAccuracy(\n",
        "                var.to(device), y_actual\n",
        "            )  # calling accuracy function to get accuracy\n",
        "            input1 = test_decoder_input_data[x : x + batchsize]\n",
        "            df = getPredictions(\n",
        "                input1, y_actual, df\n",
        "            )  # calling getPrediction function to generate prediction vanilla\n",
        "            # calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
        "                y_pred, var.reshape(-1).to(device)\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "        denom = len(test_decoder_input_data) * max_dec_len\n",
        "        test_loss = total_loss / denom  # calculating test loss\n",
        "        total_loss = 0\n",
        "        # calculating test accuracy\n",
        "        test_accuracy = total_acc / len(test_decoder_input_data)\n",
        "        test_accuracy = test_accuracy * 100\n",
        "        total_acc = 0\n",
        "        return test_loss, test_accuracy, df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NtvY0rvZSNBE"
      },
      "source": [
        "##**Function for validation data** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVsS_8E7m66V"
      },
      "outputs": [],
      "source": [
        "def getValidation(\n",
        "    attention,\n",
        "    val_encoder_input_data,\n",
        "    val_decoder_input_data,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    batchsize,\n",
        "    hidden_size,\n",
        "    embedding_size,\n",
        "    no_of_layers,\n",
        "):\n",
        "    with torch.no_grad():\n",
        "        temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "        enc_hidden = temp\n",
        "        enc_cell = temp\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for x in range(0, len(val_encoder_input_data), batchsize):\n",
        "            y_pred = []\n",
        "            y_actual = []\n",
        "            loss = 0\n",
        "            # input for encoder\n",
        "            input_tensor = getBatchData(val_encoder_input_data, batchsize, x).to(device)\n",
        "            # calling encoder forward function\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            output = getSplit(output, hidden_size)\n",
        "            # input for first hidden state in decoder\n",
        "            input = (\n",
        "                val_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )\n",
        "            # calling resize because encoder is bidirectional\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            k = 0\n",
        "            temp1 = output if attention else hiddenj\n",
        "            # ruuning while loop for max no of characters in decoder data\n",
        "            while k < max_dec_len:\n",
        "                output1, (hidden, cell) = decoder.forward(input, hidden, cell, temp1)\n",
        "                output2 = decoder.softmax(output1)\n",
        "                output3 = torch.argmax(output2, dim=2)\n",
        "                y_pred.append(output1)  # storing decoder predicted value\n",
        "                y_actual.append(output3)  # storing decoder predicted value index\n",
        "                input = output3\n",
        "                k += 1\n",
        "            # flattening the tensor\n",
        "            y_pred = getConcatenation(y_pred).reshape(\n",
        "                max_dec_len * batchsize, len(target_token_index)\n",
        "            )\n",
        "            y_actual = getConcatenation(y_actual)\n",
        "            var = val_decoder_input_data[x : x + batchsize]\n",
        "            total_acc += getAccuracy(\n",
        "                var.to(device), y_actual\n",
        "            )  # calling accuracy function to get accuracy\n",
        "            # calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
        "                y_pred, var.reshape(-1).to(device)\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "        denom = len(val_decoder_input_data) * max_dec_len\n",
        "        val_loss = total_loss / denom  # calculating val loss\n",
        "        total_loss = 0\n",
        "        # calculating val accuracy\n",
        "        val_accuracy = total_acc / len(val_decoder_input_data)\n",
        "        val_accuracy = val_accuracy * 100\n",
        "        total_acc = 0\n",
        "        return val_loss, val_accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-U9MfPm55Tez"
      },
      "source": [
        "##**Train function for Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEseFzv2PRME"
      },
      "outputs": [],
      "source": [
        "def attentiontrain(\n",
        "    rnn, batchsize, hidden_size, embedding_size, no_of_layers, dropout, epochs\n",
        "):\n",
        "    teacher_ratio = 0.5\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    learning_rate = 0.001\n",
        "    # calling encoder and attention\n",
        "    encoder = Encoder(rnn, embedding_size, hidden_size, no_of_layers, dropout).to(\n",
        "        device\n",
        "    )\n",
        "    decoder = Attention(\n",
        "        rnn, embedding_size, hidden_size, no_of_layers, dropout, batchsize\n",
        "    ).to(device)\n",
        "    opt_encoder = optim.Adam(encoder.parameters(), learning_rate)\n",
        "    opt_decoder = optim.Adam(decoder.parameters(), learning_rate)\n",
        "    loss = 0\n",
        "    # running for loop epochs no of times\n",
        "    for i in range(epochs):\n",
        "        print(\"Epoch---\", i + 1, end=\" \")\n",
        "        for x in range(0, len(train_encoder_input_data), batchsize):\n",
        "            y_pred = []  # to store predicted value by decoder to calculate loss\n",
        "            y_val = (\n",
        "                []\n",
        "            )  # to store index of predicted value by decoder to calculate accuracy\n",
        "            # initially initializing with zeroes\n",
        "            hidden_input = torch.zeros(no_of_layers, batchsize, hidden_size).to(device)\n",
        "            temp = torch.zeros(2 * no_of_layers, batchsize, hidden_size).to(device)\n",
        "            # getting batchsize amount of encoder data\n",
        "            input_tensor = getBatchData(train_encoder_input_data, batchsize, x).to(\n",
        "                device\n",
        "            )\n",
        "            enc_hidden = temp\n",
        "            enc_cell = temp\n",
        "            if input_tensor.size()[0] < batchsize:\n",
        "                break\n",
        "            # calling encoderforward\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, enc_hidden, enc_cell)\n",
        "            # to get batchsize amount of decoder input data for first hidden state\n",
        "            input = (\n",
        "                train_decoder_input_data[x : x + batchsize, 0]\n",
        "                .to(device)\n",
        "                .reshape(batchsize, 1)\n",
        "            )\n",
        "            # doing the resizeing for bidirectional implementation\n",
        "            hidden = getResize(hidden, 2, no_of_layers, batchsize, hidden_size)\n",
        "            cell = getResize(cell, 2, no_of_layers, batchsize, hidden_size)\n",
        "            hiddenj = hidden\n",
        "            # using teacher forcing\n",
        "            teacher_forcing = True if random.random() < teacher_ratio else False\n",
        "            k = 0\n",
        "            use_teacher_forcing = True if random.random() < teacher_ratio else False\n",
        "            if teacher_forcing:\n",
        "                # runing while loop for max no of characters in decoder data\n",
        "                while k < max_dec_len:\n",
        "                    output1, (hidden1, cell1) = decoder.forward(\n",
        "                        input, hidden, cell, hiddenj\n",
        "                    )  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    y_pred.append(output1)  # calling decoder forward\n",
        "                    y_val.append(output3)  # storing decoder predicted value index\n",
        "                    # giving groung truth data for next input\n",
        "                    input = (\n",
        "                        train_decoder_input_data[x : x + batchsize, i]\n",
        "                        .to(device)\n",
        "                        .reshape(batchsize, 1)\n",
        "                    )\n",
        "                    k += 1\n",
        "            else:\n",
        "                while k < max_dec_len:\n",
        "                    output1, (hidden, cell) = decoder.forward(\n",
        "                        input, hidden, cell, hiddenj\n",
        "                    )  # calling decoder forward\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    y_pred.append(output1)\n",
        "                    y_val.append(output3)\n",
        "                    # giving last output as next input\n",
        "                    input = output3\n",
        "                    k += 1\n",
        "            # flattening the tensor\n",
        "            y_pred = (\n",
        "                getConcatenation(y_pred)\n",
        "                .to(device)\n",
        "                .reshape(max_dec_len * batchsize, len(target_token_index))\n",
        "            )\n",
        "            y_val = getConcatenation(y_val)\n",
        "            var = getBatchData(train_decoder_input_data, batchsize, x)\n",
        "            # calling accuracy function to get accuracy\n",
        "            total_acc += getAccuracy(var.to(device), y_val)\n",
        "            # calculating loss\n",
        "            loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
        "                y_pred, var.reshape(-1).to(device)\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "            loss.backward(retain_graph=True)\n",
        "            # clipping the gradient\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "            opt_encoder.step()\n",
        "            opt_decoder.step()\n",
        "            opt_encoder.zero_grad()\n",
        "            opt_decoder.zero_grad()\n",
        "        denom = len(train_decoder_input_data) * max_dec_len\n",
        "        training_loss = total_loss / denom  # calculating training loss\n",
        "        # calculating training accuracy\n",
        "        training_accuracy = (total_acc / len(train_decoder_input_data)) * 100\n",
        "        # calling getValidation to get validation loss and accuracy\n",
        "        validation_loss, validation_accuracy = valevaluate(\n",
        "            False,\n",
        "            val_encoder_input_data,\n",
        "            val_decoder_input_data,\n",
        "            encoder,\n",
        "            decoder,\n",
        "            batchsize,\n",
        "            hidden_size,\n",
        "            embedding_size,\n",
        "            no_of_layers,\n",
        "        )\n",
        "        # test_loss,test_accuracy = Evaluate(False,test_encoder_input_data,test_decoder_input_data,encoder,decoder,batchsize,hidden_size,embedding_size,no_of_layers)\n",
        "        print(\n",
        "            \"  loss = \",\n",
        "            training_loss,\n",
        "            \"  accuracy = \",\n",
        "            training_accuracy,\n",
        "            \"   validation loss= \",\n",
        "            validation_loss,\n",
        "            \"  validation accuaracy= \",\n",
        "            validation_accuracy,\n",
        "        )\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "    return encoder, decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxH0Z0St5xsC"
      },
      "outputs": [],
      "source": [
        "# function for sweep with attention\n",
        "def withattention():\n",
        "    wandb.init(project=\"DL-Assignment3\")\n",
        "    config = wandb.config\n",
        "    wandb.run.name = (\n",
        "        \"_attention_cell_type_{}_bidirec_{}_layers_{}_batchsize_{}_hidden_{}\".format(\n",
        "            config.cell_type,\n",
        "            config.bidirectional,\n",
        "            config.no_of_layers,\n",
        "            config.batchsize,\n",
        "            config.hidden_size,\n",
        "        )\n",
        "    )\n",
        "    hidden_size = config.hidden_size\n",
        "    char_embed_size = config.input_embedding_size\n",
        "    no_of_layers = config.no_of_layers\n",
        "    epochs = config.epochs\n",
        "    batchsize = config.batchsize\n",
        "    dropout = config.dropout  # using dropout\n",
        "    rnn = config.cell_type\n",
        "    # calling attention train function\n",
        "    Encoder1, Decoder1 = attentiontrain(\n",
        "        batchsize, hidden_size, char_embed_size, no_of_layers, dropout, epochs, rnn\n",
        "    )\n",
        "    attentionplot(\n",
        "        True,\n",
        "        test_eng_word,\n",
        "        test_hin_word,\n",
        "        Encoder1,\n",
        "        Decoder1,\n",
        "        1,\n",
        "        hidden_size,\n",
        "        char_embed_size,\n",
        "        no_of_layers,\n",
        "        True,\n",
        "    )\n",
        "    gpu_usage()\n",
        "    torch.cuda.empty_cache()\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "    gpu_usage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XQBvw6U57SD"
      },
      "outputs": [],
      "source": [
        "sweep_configuration = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"goal\": \"maximize\", \"name\": \"validation_accuracy\"},\n",
        "    \"parameters\": {\n",
        "        \"batchsize\": {\"values\": [64, 128, 512, 1024]},\n",
        "        \"input_embedding_size\": {\"values\": [256, 512, 1024]},\n",
        "        \"no_of_layers\": {\"values\": [2, 3, 4, 5, 6]},\n",
        "        \"hidden_size\": {\"values\": [128, 256, 512, 1024]},\n",
        "        \"cell_type\": {\"values\": [\"LSTM\", \"RNN\", \"GRU\"]},\n",
        "        \"bidirectional\": {\"values\": [\"Yes\"]},\n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3, 0.4, 0.5]},\n",
        "        \"epochs\": {\"values\": [10, 20, 30]},\n",
        "    },\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"DL-Assignment3\")\n",
        "wandb.agent(sweep_id, function=main, count=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJFe6lvLsM7Q"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy, predictions = Evaluate(\n",
        "    False,\n",
        "    test_encoder_input_data,\n",
        "    test_decoder_input_data,\n",
        "    Encoder1,\n",
        "    Decoder1,\n",
        "    256,\n",
        "    256,\n",
        "    256,\n",
        "    2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxulgMdwtQAu"
      },
      "outputs": [],
      "source": [
        "predictions.to_excel(\"testing.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
